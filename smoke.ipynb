{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data from the 2014 American National Youth Tobacco Survey\n",
    "\n",
    "**Objective:** Create an analysis report and predictive model on the smoking habits of American Youth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "smokeData = pd.read_csv('smokeData.csv')\n",
    "smokeCol = smokeData.columns.values.tolist()\n",
    "len(smokeCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22007"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(smokeData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a total of 163 variables and 22 thousand instances in this dataset. There is no way we're going to use all of these variables to model our data so we should first manually go through all the variables and learn what they actually represent. Along with the data provided by the CDC is the Codebook for the dataset which tells you exactly what each variable represents and the proportion of reponses to each variable.\n",
    "\n",
    "Right off the bat we can see that our data is very specific, for example it separates the act of smoking into several different variables based on the exact method of smoking. These include: cigarettes, cigars, cigarillos, chewing tabacco, snuff etc. While most variables seem to be somewhat related to our topic of interest, many of them are not that useful and just create clutter as a result. For example, while variables such as if the respondent thinks it's cool to smoke directly affects whether they have smoked before or not, we usually wouldn't know the feelings and thoughts of the individual we're trying to predict.\n",
    "\n",
    "So instead we'll be analyzing and using the most basic, concrete, and easy to obtain variables for an individual to build our model, namely: Age, Sex, Grade, Race, and RuralUrban (whether the individual lives in a urban or rural area)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Race</th>\n",
       "      <th>RuralUrban</th>\n",
       "      <th>ever_cigarettes</th>\n",
       "      <th>ever_cigars_cigarillos_or</th>\n",
       "      <th>Ever_chewing_tobacco_snuf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.0</td>\n",
       "      <td>M</td>\n",
       "      <td>2.0</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>Urban</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.0</td>\n",
       "      <td>F</td>\n",
       "      <td>2.0</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>Urban</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.0</td>\n",
       "      <td>M</td>\n",
       "      <td>2.0</td>\n",
       "      <td>native</td>\n",
       "      <td>Urban</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.0</td>\n",
       "      <td>M</td>\n",
       "      <td>2.0</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>Urban</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.0</td>\n",
       "      <td>M</td>\n",
       "      <td>2.0</td>\n",
       "      <td>native</td>\n",
       "      <td>Urban</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Sex  Grade      Race RuralUrban ever_cigarettes  \\\n",
       "0  13.0   M    2.0  hispanic      Urban           False   \n",
       "1  12.0   F    2.0  hispanic      Urban           False   \n",
       "2  14.0   M    2.0    native      Urban           False   \n",
       "3  13.0   M    2.0  hispanic      Urban           False   \n",
       "4  14.0   M    2.0    native      Urban            True   \n",
       "\n",
       "  ever_cigars_cigarillos_or Ever_chewing_tobacco_snuf  \n",
       "0                     False                     False  \n",
       "1                     False                     False  \n",
       "2                     False                     False  \n",
       "3                     False                     False  \n",
       "4                     False                     False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = smokeData[['Age','Sex','Grade','Race','RuralUrban','ever_cigarettes','ever_cigars_cigarillos_or',\n",
    "                'Ever_chewing_tobacco_snuf']].copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22007 entries, 0 to 22006\n",
      "Data columns (total 8 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Age                        21850 non-null  float64\n",
      " 1   Sex                        21795 non-null  object \n",
      " 2   Grade                      21836 non-null  float64\n",
      " 3   Race                       20800 non-null  object \n",
      " 4   RuralUrban                 22007 non-null  object \n",
      " 5   ever_cigarettes            21565 non-null  object \n",
      " 6   ever_cigars_cigarillos_or  21492 non-null  object \n",
      " 7   Ever_chewing_tobacco_snuf  21528 non-null  object \n",
      "dtypes: float64(2), object(6)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Race</th>\n",
       "      <th>RuralUrban</th>\n",
       "      <th>ever_cigarettes</th>\n",
       "      <th>ever_cigars_cigarillos_or</th>\n",
       "      <th>Ever_chewing_tobacco_snuf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21850.000000</td>\n",
       "      <td>21795</td>\n",
       "      <td>21836.000000</td>\n",
       "      <td>20800</td>\n",
       "      <td>22007</td>\n",
       "      <td>21565</td>\n",
       "      <td>21492</td>\n",
       "      <td>21528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>white</td>\n",
       "      <td>Urban</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>11150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9893</td>\n",
       "      <td>11811</td>\n",
       "      <td>16709</td>\n",
       "      <td>17696</td>\n",
       "      <td>19812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.499588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.828586</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.087983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.991755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Age    Sex         Grade   Race RuralUrban ever_cigarettes  \\\n",
       "count   21850.000000  21795  21836.000000  20800      22007           21565   \n",
       "unique           NaN      2           NaN      6          2               2   \n",
       "top              NaN      M           NaN  white      Urban           False   \n",
       "freq             NaN  11150           NaN   9893      11811           16709   \n",
       "mean       14.499588    NaN      3.828586    NaN        NaN             NaN   \n",
       "std         2.087983    NaN      1.991755    NaN        NaN             NaN   \n",
       "min         9.000000    NaN      1.000000    NaN        NaN             NaN   \n",
       "25%        13.000000    NaN      2.000000    NaN        NaN             NaN   \n",
       "50%        14.000000    NaN      4.000000    NaN        NaN             NaN   \n",
       "75%        16.000000    NaN      6.000000    NaN        NaN             NaN   \n",
       "max        19.000000    NaN      8.000000    NaN        NaN             NaN   \n",
       "\n",
       "       ever_cigars_cigarillos_or Ever_chewing_tobacco_snuf  \n",
       "count                      21492                     21528  \n",
       "unique                         2                         2  \n",
       "top                        False                     False  \n",
       "freq                       17696                     19812  \n",
       "mean                         NaN                       NaN  \n",
       "std                          NaN                       NaN  \n",
       "min                          NaN                       NaN  \n",
       "25%                          NaN                       NaN  \n",
       "50%                          NaN                       NaN  \n",
       "75%                          NaN                       NaN  \n",
       "max                          NaN                       NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we check for in every dataset is missing values and it looks like we have missing values in every column except for RuralUrban. There are many ways of dealing with missing values; taking the response variable 'ever_cigarettes' for example, it is a binary variable that represents whether the individual has ever smoked cigarettes or not. Because it is a binary variable, there are really only 2 ways we can deal with it. Either fill them in with values or remove all of them. The first option is okay, but I think the second option is the best because we have 22 thousand rows in total and we're only missing 500 rows which isn't a lot by comparison; we won't be losing that much information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Race</th>\n",
       "      <th>RuralUrban</th>\n",
       "      <th>ever_cigarettes</th>\n",
       "      <th>ever_cigars_cigarillos_or</th>\n",
       "      <th>Ever_chewing_tobacco_snuf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21478.000000</td>\n",
       "      <td>21426</td>\n",
       "      <td>21465.000000</td>\n",
       "      <td>20493</td>\n",
       "      <td>21565</td>\n",
       "      <td>21565</td>\n",
       "      <td>21194</td>\n",
       "      <td>21213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>white</td>\n",
       "      <td>Urban</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9819</td>\n",
       "      <td>11571</td>\n",
       "      <td>16709</td>\n",
       "      <td>17506</td>\n",
       "      <td>19549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.503539</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.833636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.084909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.991209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Age    Sex         Grade   Race RuralUrban ever_cigarettes  \\\n",
       "count   21478.000000  21426  21465.000000  20493      21565           21565   \n",
       "unique           NaN      2           NaN      6          2               2   \n",
       "top              NaN      M           NaN  white      Urban           False   \n",
       "freq             NaN  10921           NaN   9819      11571           16709   \n",
       "mean       14.503539    NaN      3.833636    NaN        NaN             NaN   \n",
       "std         2.084909    NaN      1.991209    NaN        NaN             NaN   \n",
       "min         9.000000    NaN      1.000000    NaN        NaN             NaN   \n",
       "25%        13.000000    NaN      2.000000    NaN        NaN             NaN   \n",
       "50%        14.000000    NaN      4.000000    NaN        NaN             NaN   \n",
       "75%        16.000000    NaN      6.000000    NaN        NaN             NaN   \n",
       "max        19.000000    NaN      8.000000    NaN        NaN             NaN   \n",
       "\n",
       "       ever_cigars_cigarillos_or Ever_chewing_tobacco_snuf  \n",
       "count                      21194                     21213  \n",
       "unique                         2                         2  \n",
       "top                        False                     False  \n",
       "freq                       17506                     19549  \n",
       "mean                         NaN                       NaN  \n",
       "std                          NaN                       NaN  \n",
       "min                          NaN                       NaN  \n",
       "25%                          NaN                       NaN  \n",
       "50%                          NaN                       NaN  \n",
       "75%                          NaN                       NaN  \n",
       "max                          NaN                       NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(subset=['ever_cigarettes'], inplace = True)\n",
    "df.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing the same for Sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Race</th>\n",
       "      <th>RuralUrban</th>\n",
       "      <th>ever_cigarettes</th>\n",
       "      <th>ever_cigars_cigarillos_or</th>\n",
       "      <th>Ever_chewing_tobacco_snuf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21393.000000</td>\n",
       "      <td>21426</td>\n",
       "      <td>21401.000000</td>\n",
       "      <td>20416</td>\n",
       "      <td>21426</td>\n",
       "      <td>21426</td>\n",
       "      <td>21065</td>\n",
       "      <td>21086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>white</td>\n",
       "      <td>Urban</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9796</td>\n",
       "      <td>11468</td>\n",
       "      <td>16606</td>\n",
       "      <td>17404</td>\n",
       "      <td>19435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.503389</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.833185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.084643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.990427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Age    Sex         Grade   Race RuralUrban ever_cigarettes  \\\n",
       "count   21393.000000  21426  21401.000000  20416      21426           21426   \n",
       "unique           NaN      2           NaN      6          2               2   \n",
       "top              NaN      M           NaN  white      Urban           False   \n",
       "freq             NaN  10921           NaN   9796      11468           16606   \n",
       "mean       14.503389    NaN      3.833185    NaN        NaN             NaN   \n",
       "std         2.084643    NaN      1.990427    NaN        NaN             NaN   \n",
       "min         9.000000    NaN      1.000000    NaN        NaN             NaN   \n",
       "25%        13.000000    NaN      2.000000    NaN        NaN             NaN   \n",
       "50%        14.000000    NaN      4.000000    NaN        NaN             NaN   \n",
       "75%        16.000000    NaN      6.000000    NaN        NaN             NaN   \n",
       "max        19.000000    NaN      8.000000    NaN        NaN             NaN   \n",
       "\n",
       "       ever_cigars_cigarillos_or Ever_chewing_tobacco_snuf  \n",
       "count                      21065                     21086  \n",
       "unique                         2                         2  \n",
       "top                        False                     False  \n",
       "freq                       17404                     19435  \n",
       "mean                         NaN                       NaN  \n",
       "std                          NaN                       NaN  \n",
       "min                          NaN                       NaN  \n",
       "25%                          NaN                       NaN  \n",
       "50%                          NaN                       NaN  \n",
       "75%                          NaN                       NaN  \n",
       "max                          NaN                       NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(subset=['Sex'], inplace = True)\n",
    "df.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we could do the same thing for Race, except we would be removing over 1000 data points and that would lead to quite a lot of data loss. Instead of removing the missing values, we can try some different methods of filling them in. Since Race is a categorical variable, we can fill them in using different strategies such as mode or a specific pattern(using sklearn Imputer or pandas interpolate or fillna), or one-hot encode the variable and then set 'everything' to 0 (where appropraite and makes sense), or we can even train a classifier using the other variables to predict the missing values if we had the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x24b6658fac8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = 'Race', data = df, order = df['Race'].value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar graph using pandas and matplotlib instead of seaborn\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# df['Race'].value_counts().plot(kind=\"bar\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be filling the missing values using the mode and see how it does down the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Race</th>\n",
       "      <th>RuralUrban</th>\n",
       "      <th>ever_cigarettes</th>\n",
       "      <th>ever_cigars_cigarillos_or</th>\n",
       "      <th>Ever_chewing_tobacco_snuf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21393.000000</td>\n",
       "      <td>21426</td>\n",
       "      <td>21401.000000</td>\n",
       "      <td>21426</td>\n",
       "      <td>21426</td>\n",
       "      <td>21426</td>\n",
       "      <td>21065</td>\n",
       "      <td>21086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>white</td>\n",
       "      <td>Urban</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9796</td>\n",
       "      <td>11468</td>\n",
       "      <td>16606</td>\n",
       "      <td>17404</td>\n",
       "      <td>19435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.503389</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.833185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.084643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.990427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Age    Sex         Grade   Race RuralUrban ever_cigarettes  \\\n",
       "count   21393.000000  21426  21401.000000  21426      21426           21426   \n",
       "unique           NaN      2           NaN      7          2               2   \n",
       "top              NaN      M           NaN  white      Urban           False   \n",
       "freq             NaN  10921           NaN   9796      11468           16606   \n",
       "mean       14.503389    NaN      3.833185    NaN        NaN             NaN   \n",
       "std         2.084643    NaN      1.990427    NaN        NaN             NaN   \n",
       "min         9.000000    NaN      1.000000    NaN        NaN             NaN   \n",
       "25%        13.000000    NaN      2.000000    NaN        NaN             NaN   \n",
       "50%        14.000000    NaN      4.000000    NaN        NaN             NaN   \n",
       "75%        16.000000    NaN      6.000000    NaN        NaN             NaN   \n",
       "max        19.000000    NaN      8.000000    NaN        NaN             NaN   \n",
       "\n",
       "       ever_cigars_cigarillos_or Ever_chewing_tobacco_snuf  \n",
       "count                      21065                     21086  \n",
       "unique                         2                         2  \n",
       "top                        False                     False  \n",
       "freq                       17404                     19435  \n",
       "mean                         NaN                       NaN  \n",
       "std                          NaN                       NaN  \n",
       "min                          NaN                       NaN  \n",
       "25%                          NaN                       NaN  \n",
       "50%                          NaN                       NaN  \n",
       "75%                          NaN                       NaN  \n",
       "max                          NaN                       NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fillna(value = {'Race':'White'}, inplace = True)\n",
    "df.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With numerical variables such as Age or Grade, we have a bit more options of how to fill in the missing values. Some typical strategies of filling include using: the mean, the mode, the median, (min + max)/2 etc. We'll be using the median for both Age and Grade as it produces slightly more consistent results than the mean (we won't have someone who is Grade 4.5 for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Race</th>\n",
       "      <th>RuralUrban</th>\n",
       "      <th>ever_cigarettes</th>\n",
       "      <th>ever_cigars_cigarillos_or</th>\n",
       "      <th>Ever_chewing_tobacco_snuf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21426.000000</td>\n",
       "      <td>21426</td>\n",
       "      <td>21426.000000</td>\n",
       "      <td>21426</td>\n",
       "      <td>21426</td>\n",
       "      <td>21426</td>\n",
       "      <td>21065</td>\n",
       "      <td>21086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>white</td>\n",
       "      <td>Urban</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9796</td>\n",
       "      <td>11468</td>\n",
       "      <td>16606</td>\n",
       "      <td>17404</td>\n",
       "      <td>19435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.502614</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.833380</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.083131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.989273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Age    Sex         Grade   Race RuralUrban ever_cigarettes  \\\n",
       "count   21426.000000  21426  21426.000000  21426      21426           21426   \n",
       "unique           NaN      2           NaN      7          2               2   \n",
       "top              NaN      M           NaN  white      Urban           False   \n",
       "freq             NaN  10921           NaN   9796      11468           16606   \n",
       "mean       14.502614    NaN      3.833380    NaN        NaN             NaN   \n",
       "std         2.083131    NaN      1.989273    NaN        NaN             NaN   \n",
       "min         9.000000    NaN      1.000000    NaN        NaN             NaN   \n",
       "25%        13.000000    NaN      2.000000    NaN        NaN             NaN   \n",
       "50%        14.000000    NaN      4.000000    NaN        NaN             NaN   \n",
       "75%        16.000000    NaN      6.000000    NaN        NaN             NaN   \n",
       "max        19.000000    NaN      8.000000    NaN        NaN             NaN   \n",
       "\n",
       "       ever_cigars_cigarillos_or Ever_chewing_tobacco_snuf  \n",
       "count                      21065                     21086  \n",
       "unique                         2                         2  \n",
       "top                        False                     False  \n",
       "freq                       17404                     19435  \n",
       "mean                         NaN                       NaN  \n",
       "std                          NaN                       NaN  \n",
       "min                          NaN                       NaN  \n",
       "25%                          NaN                       NaN  \n",
       "50%                          NaN                       NaN  \n",
       "75%                          NaN                       NaN  \n",
       "max                          NaN                       NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fillna(value = {'Age': 14, 'Grade': 4}, inplace = True)\n",
    "df.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we're done with dealing with the missing values, we can move on to some preliminary analysis and sanity checks.\n",
    "\n",
    "We see that:\n",
    "* We have a good split of male and female respondents as well as Rural and Urban living respondents.\n",
    "\n",
    "* The top responding race demographic was whites at about 45.7%.\n",
    "\n",
    "* Roughly 77.5% of the surveyed population have never smoked a cigarette; it's good news that the majority of our younger generation doesn't smoke.\n",
    "\n",
    "* The youngest respondents are 9 years of age and grade 1 respectively, in fact a quarter of our respondents are around 13 years of age and in grade 2.\n",
    "\n",
    "#### Let's take a closer look at the last point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.0    3528\n",
       "14.0    3194\n",
       "12.0    3010\n",
       "15.0    2879\n",
       "16.0    2852\n",
       "17.0    2797\n",
       "18.0    1647\n",
       "11.0    1305\n",
       "19.0     173\n",
       "9.0       31\n",
       "10.0      10\n",
       "Name: Age, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"ever_cigarettes\", hue=\"Age\", data=df)\n",
    "df['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[(df['Age'] < 12) & (df['ever_cigarettes'] == True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the trend is within expectations as there is a positive relationship between the number of people who have tried cigarettes and the age of the individuals. We also see a huge difference in the number of people who are 11 and under vs 12 and over and who have smoked cigarettes before. This prompts us to consider those who have smoked cigarettes and are 11 and under to be outliers in our dataset. Because it is a pretty safe assumption that most people under the age of 12 have not smoked cigarettes before, we can remove those individuals from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all respondents under age of 12 who have smoked before\n",
    "df = df.drop(df[(df['Age'] < 12) & (df['ever_cigarettes'] == True)].index)\n",
    "# need to reset index or some rows will just be missing and it'll create errors down the line\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "# Altnerative method\n",
    "# df = df[(df.Age < 12) & (df.ever_cigarettes == True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    3457\n",
       "2.0    3435\n",
       "1.0    3232\n",
       "5.0    2887\n",
       "4.0    2851\n",
       "6.0    2774\n",
       "7.0    2705\n",
       "8.0      10\n",
       "Name: Grade, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"ever_cigarettes\", hue=\"Grade\", data=df)\n",
    "df['Grade'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Age and Grade graphs look pretty good now.\n",
    "\n",
    "We also notice a capital letters problem with our Race variable resulting in an extra category, so let's fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hispanic', 'native', 'White', 'black', 'white', 'asian',\n",
       "       'pacific'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Race.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace White with white so it's consistent\n",
    "df = df.replace('White', 'white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to turn predictor variables from a dataframe into numpy array before we can use OneHotEncoder\n",
    "X = df[['Sex', 'Race', 'RuralUrban']].to_numpy()\n",
    "\n",
    "# Altnative Method\n",
    "# X = df.loc[:, ['Age', 'Sex', 'Race']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "onehot = OneHotEncoder()\n",
    "X = pd.DataFrame(onehot.fit_transform(X).toarray(), columns = onehot.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Age and Grade are highly correlated (it's easy to tell without doing any statistical tests), we should only use 1 of them in our model to avoid the multicolinearity problem. We're going to use Age over Grade because we've already removed some outliers based on Age and it is the more basic variable as everyone has an Age, but it is possible that they do not have a Grade (if they're not in school for whatever reason)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>x0_F</th>\n",
       "      <th>x0_M</th>\n",
       "      <th>x1_asian</th>\n",
       "      <th>x1_black</th>\n",
       "      <th>x1_hispanic</th>\n",
       "      <th>x1_native</th>\n",
       "      <th>x1_pacific</th>\n",
       "      <th>x1_white</th>\n",
       "      <th>x2_Rural</th>\n",
       "      <th>x2_Urban</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21346</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21347</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21348</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21349</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21350</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21351 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  x0_F  x0_M  x1_asian  x1_black  x1_hispanic  x1_native  \\\n",
       "0      13.0   0.0   1.0       0.0       0.0          1.0        0.0   \n",
       "1      12.0   1.0   0.0       0.0       0.0          1.0        0.0   \n",
       "2      14.0   0.0   1.0       0.0       0.0          0.0        1.0   \n",
       "3      13.0   0.0   1.0       0.0       0.0          1.0        0.0   \n",
       "4      14.0   0.0   1.0       0.0       0.0          0.0        1.0   \n",
       "...     ...   ...   ...       ...       ...          ...        ...   \n",
       "21346  17.0   0.0   1.0       0.0       0.0          1.0        0.0   \n",
       "21347  16.0   1.0   0.0       0.0       0.0          0.0        0.0   \n",
       "21348  19.0   0.0   1.0       0.0       1.0          0.0        0.0   \n",
       "21349  18.0   1.0   0.0       0.0       0.0          0.0        0.0   \n",
       "21350  18.0   1.0   0.0       0.0       1.0          0.0        0.0   \n",
       "\n",
       "       x1_pacific  x1_white  x2_Rural  x2_Urban  \n",
       "0             0.0       0.0       0.0       1.0  \n",
       "1             0.0       0.0       0.0       1.0  \n",
       "2             0.0       0.0       0.0       1.0  \n",
       "3             0.0       0.0       0.0       1.0  \n",
       "4             0.0       0.0       0.0       1.0  \n",
       "...           ...       ...       ...       ...  \n",
       "21346         0.0       0.0       1.0       0.0  \n",
       "21347         0.0       1.0       1.0       0.0  \n",
       "21348         0.0       0.0       1.0       0.0  \n",
       "21349         0.0       1.0       1.0       0.0  \n",
       "21350         0.0       0.0       1.0       0.0  \n",
       "\n",
       "[21351 rows x 11 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.insert(0, 'Age', df[['Age']], True)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick check to make sure we correctly encoded the predictor categorical variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Race</th>\n",
       "      <th>RuralUrban</th>\n",
       "      <th>ever_cigarettes</th>\n",
       "      <th>ever_cigars_cigarillos_or</th>\n",
       "      <th>Ever_chewing_tobacco_snuf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21346</th>\n",
       "      <td>17.0</td>\n",
       "      <td>M</td>\n",
       "      <td>7.0</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>Rural</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21347</th>\n",
       "      <td>16.0</td>\n",
       "      <td>F</td>\n",
       "      <td>5.0</td>\n",
       "      <td>white</td>\n",
       "      <td>Rural</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21348</th>\n",
       "      <td>19.0</td>\n",
       "      <td>M</td>\n",
       "      <td>8.0</td>\n",
       "      <td>black</td>\n",
       "      <td>Rural</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21349</th>\n",
       "      <td>18.0</td>\n",
       "      <td>F</td>\n",
       "      <td>7.0</td>\n",
       "      <td>white</td>\n",
       "      <td>Rural</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21350</th>\n",
       "      <td>18.0</td>\n",
       "      <td>F</td>\n",
       "      <td>7.0</td>\n",
       "      <td>black</td>\n",
       "      <td>Rural</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age Sex  Grade      Race RuralUrban  ever_cigarettes  \\\n",
       "21346  17.0   M    7.0  hispanic      Rural             True   \n",
       "21347  16.0   F    5.0     white      Rural            False   \n",
       "21348  19.0   M    8.0     black      Rural             True   \n",
       "21349  18.0   F    7.0     white      Rural            False   \n",
       "21350  18.0   F    7.0     black      Rural             True   \n",
       "\n",
       "      ever_cigars_cigarillos_or Ever_chewing_tobacco_snuf  \n",
       "21346                      True                     False  \n",
       "21347                     False                     False  \n",
       "21348                      True                     False  \n",
       "21349                      True                     False  \n",
       "21350                     False                     False  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.head()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = df[['ever_cigarettes']].to_numpy()\n",
    "y = le.fit_transform(y.ravel())\n",
    "# 0 - False, 1 - True\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21351, 11)\n",
      "(21351,)\n"
     ]
    }
   ],
   "source": [
    "X = X.to_numpy()\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "gridsearch = GridSearchCV(log_clf, param_grid, n_jobs = -1)\n",
    "\n",
    "gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7775761124121778"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7780379302271131"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_est = gridsearch.best_estimator_\n",
    "best_est.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.34518676, -0.0581947 ,  0.05814976, -0.0688631 , -0.02141137,\n",
       "         0.05101119,  0.01181007,  0.00468759,  0.02272068,  0.1146945 ,\n",
       "        -0.11473944]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_est.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.41124723])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_est.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our resulting Logistic Model is the following:\n",
    "\n",
    "$$logit(p_i) = -6.48 + 0.35*Age - 0.05*SexFemale + 0.05*SexMale - 0.07*RaceAsian - 0.03*RaceBlack + 0.07*RaceHispanic + 0.02*RaceNative + 0.006RacePacific + 0.01*RaceWhite + 0.11*Rural - 0.11*Urban$$\n",
    "\n",
    "where $p_i$ is the probability that the i-th respondent has ever smoked cigarettes.\n",
    "\n",
    "This model is able to reach 77.7% accuracy on the test set.\n",
    "\n",
    "From the model, it seems that the most important variable in determining the probability that a respondents smokes or not is their age; the older they are, the more likely they are to have smoked a cigarette before. We also notice that females are less likely to smoke than males, people who live in Urban areas are less likely to smoke than  those who live in Rural areas, and among the 6 races in our data, whites are the most likely to smoke and asians are the least likely. We do have to keep in mind that the the distribution of Race was heavily skewed for whites as almost 50% of respondents were whites, because of this, we should take the last result with a grain of salt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying out other models: Decision Tree, Random Forest and ANN.\n",
    "\n",
    "Let's see if we can achieve better results using some other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7765807962529273"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "dec_tree = DecisionTreeClassifier()\n",
    "\n",
    "param_grid = {'max_depth': [100, 300, 500, 800, 1000, 1500, 2000]}\n",
    "\n",
    "gridsearch = GridSearchCV(dec_tree, param_grid, n_jobs = -1)\n",
    "\n",
    "gridsearch.fit(X_train, y_train)\n",
    "\n",
    "gridsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 100}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7768149882903981"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_forest = RandomForestClassifier()\n",
    "\n",
    "param_grid = {'n_estimators': [100, 300, 500, 800, 1000], 'max_depth': [100, 200, 300]}\n",
    "\n",
    "gridsearch = GridSearchCV(rnd_forest, param_grid, n_jobs = -1)\n",
    "\n",
    "gridsearch.fit(X_train, y_train)\n",
    "\n",
    "gridsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 300, 'n_estimators': 500}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Split training data into training and validation set\n",
    "X_train_part, X_valid, y_train_part, y_valid = train_test_split(X_train, y_train, test_size = 0.2)\n",
    "\n",
    "simple_nn = keras.models.Sequential()\n",
    "\n",
    "simple_nn.add(keras.layers.Dense(100, activation = 'relu', input_shape = (11,)))\n",
    "simple_nn.add(keras.layers.Dense(100, activation = 'relu'))\n",
    "simple_nn.add(keras.layers.Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 100)               1200      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 11,401\n",
      "Trainable params: 11,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple_nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already tried learning rate of 0.01 and 0.001 to the same effect.\n",
    "optimizer = keras.optimizers.SGD(lr = 0.0003)\n",
    "simple_nn.compile(loss=\"binary_crossentropy\", optimizer = optimizer, metrics = ['accuracy'])\n",
    "\n",
    "# callbacks for early stopping and model checkpoint\n",
    "\n",
    "# stops training after 20 epochs of no validation loss improvement\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "\n",
    "# Saves the model and its weights with the best validation loss\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"simple_nn.h5\", save_best_only=True)\n",
    "\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13664 samples, validate on 3416 samples\n",
      "Epoch 1/100\n",
      "13664/13664 [==============================] - 1s 62us/sample - loss: 0.5834 - accuracy: 0.7404 - val_loss: 0.5410 - val_accuracy: 0.7878\n",
      "Epoch 2/100\n",
      "13664/13664 [==============================] - 1s 46us/sample - loss: 0.5550 - accuracy: 0.7749 - val_loss: 0.5397 - val_accuracy: 0.7878\n",
      "Epoch 3/100\n",
      "13664/13664 [==============================] - 1s 45us/sample - loss: 0.5541 - accuracy: 0.7749 - val_loss: 0.5381 - val_accuracy: 0.7878\n",
      "Epoch 4/100\n",
      "13664/13664 [==============================] - 1s 46us/sample - loss: 0.5531 - accuracy: 0.7749 - val_loss: 0.5374 - val_accuracy: 0.7878\n",
      "Epoch 5/100\n",
      "13664/13664 [==============================] - 1s 46us/sample - loss: 0.5526 - accuracy: 0.7749 - val_loss: 0.5367 - val_accuracy: 0.7878\n",
      "Epoch 6/100\n",
      "13664/13664 [==============================] - 1s 45us/sample - loss: 0.5520 - accuracy: 0.7749 - val_loss: 0.5368 - val_accuracy: 0.7878\n",
      "Epoch 7/100\n",
      "13664/13664 [==============================] - 1s 45us/sample - loss: 0.5514 - accuracy: 0.7749 - val_loss: 0.5357 - val_accuracy: 0.7878\n",
      "Epoch 8/100\n",
      "13664/13664 [==============================] - 1s 44us/sample - loss: 0.5509 - accuracy: 0.7749 - val_loss: 0.5352 - val_accuracy: 0.7878\n",
      "Epoch 9/100\n",
      "13664/13664 [==============================] - 1s 45us/sample - loss: 0.5503 - accuracy: 0.7749 - val_loss: 0.5370 - val_accuracy: 0.7878\n",
      "Epoch 10/100\n",
      "13664/13664 [==============================] - 1s 102us/sample - loss: 0.5501 - accuracy: 0.7749 - val_loss: 0.5344 - val_accuracy: 0.7878\n",
      "Epoch 11/100\n",
      "13664/13664 [==============================] - 1s 43us/sample - loss: 0.5494 - accuracy: 0.7749 - val_loss: 0.5346 - val_accuracy: 0.7878\n",
      "Epoch 12/100\n",
      "13664/13664 [==============================] - 1s 44us/sample - loss: 0.5492 - accuracy: 0.7749 - val_loss: 0.5340 - val_accuracy: 0.7878\n",
      "Epoch 13/100\n",
      "13664/13664 [==============================] - 1s 44us/sample - loss: 0.5487 - accuracy: 0.7749 - val_loss: 0.5331 - val_accuracy: 0.7878\n",
      "Epoch 14/100\n",
      "13664/13664 [==============================] - 1s 44us/sample - loss: 0.5485 - accuracy: 0.7749 - val_loss: 0.5333 - val_accuracy: 0.7878\n",
      "Epoch 15/100\n",
      "13664/13664 [==============================] - 1s 47us/sample - loss: 0.5480 - accuracy: 0.7749 - val_loss: 0.5346 - val_accuracy: 0.7878\n",
      "Epoch 16/100\n",
      "13664/13664 [==============================] - 1s 45us/sample - loss: 0.5476 - accuracy: 0.7749 - val_loss: 0.5323 - val_accuracy: 0.7878\n",
      "Epoch 17/100\n",
      "13664/13664 [==============================] - 1s 44us/sample - loss: 0.5472 - accuracy: 0.7749 - val_loss: 0.5331 - val_accuracy: 0.7878\n",
      "Epoch 18/100\n",
      "13664/13664 [==============================] - 1s 56us/sample - loss: 0.5469 - accuracy: 0.7749 - val_loss: 0.5317 - val_accuracy: 0.7878\n",
      "Epoch 19/100\n",
      "13664/13664 [==============================] - 1s 46us/sample - loss: 0.5464 - accuracy: 0.7749 - val_loss: 0.5311 - val_accuracy: 0.7878\n",
      "Epoch 20/100\n",
      "13664/13664 [==============================] - 1s 46us/sample - loss: 0.5460 - accuracy: 0.7749 - val_loss: 0.5315 - val_accuracy: 0.7878\n",
      "Epoch 21/100\n",
      "13664/13664 [==============================] - 1s 46us/sample - loss: 0.5458 - accuracy: 0.7749 - val_loss: 0.5305 - val_accuracy: 0.7878\n",
      "Epoch 22/100\n",
      "13664/13664 [==============================] - 1s 46us/sample - loss: 0.5454 - accuracy: 0.7749 - val_loss: 0.5304 - val_accuracy: 0.7878\n",
      "Epoch 23/100\n",
      "13664/13664 [==============================] - 1s 46us/sample - loss: 0.5449 - accuracy: 0.7749 - val_loss: 0.5301 - val_accuracy: 0.7878\n",
      "Epoch 24/100\n",
      "13664/13664 [==============================] - 1s 46us/sample - loss: 0.5445 - accuracy: 0.7749 - val_loss: 0.5309 - val_accuracy: 0.7878\n",
      "Epoch 25/100\n",
      "13664/13664 [==============================] - 1s 48us/sample - loss: 0.5444 - accuracy: 0.7749 - val_loss: 0.5296 - val_accuracy: 0.7878\n",
      "Epoch 26/100\n",
      "13664/13664 [==============================] - 1s 48us/sample - loss: 0.5440 - accuracy: 0.7749 - val_loss: 0.5295 - val_accuracy: 0.7878\n",
      "Epoch 27/100\n",
      "13664/13664 [==============================] - 1s 47us/sample - loss: 0.5436 - accuracy: 0.7749 - val_loss: 0.5291 - val_accuracy: 0.7878\n",
      "Epoch 28/100\n",
      "13664/13664 [==============================] - 1s 48us/sample - loss: 0.5433 - accuracy: 0.7749 - val_loss: 0.5282 - val_accuracy: 0.7878\n",
      "Epoch 29/100\n",
      "13664/13664 [==============================] - 1s 46us/sample - loss: 0.5428 - accuracy: 0.7749 - val_loss: 0.5278 - val_accuracy: 0.7878\n",
      "Epoch 30/100\n",
      "13664/13664 [==============================] - 1s 48us/sample - loss: 0.5424 - accuracy: 0.7749 - val_loss: 0.5281 - val_accuracy: 0.7878\n",
      "Epoch 31/100\n",
      "13664/13664 [==============================] - 1s 46us/sample - loss: 0.5422 - accuracy: 0.7749 - val_loss: 0.5274 - val_accuracy: 0.7878\n",
      "Epoch 32/100\n",
      "13664/13664 [==============================] - 1s 46us/sample - loss: 0.5419 - accuracy: 0.7749 - val_loss: 0.5271 - val_accuracy: 0.7878\n",
      "Epoch 33/100\n",
      "13664/13664 [==============================] - 1s 46us/sample - loss: 0.5414 - accuracy: 0.7749 - val_loss: 0.5273 - val_accuracy: 0.7878\n",
      "Epoch 34/100\n",
      "13664/13664 [==============================] - 1s 49us/sample - loss: 0.5411 - accuracy: 0.7749 - val_loss: 0.5266 - val_accuracy: 0.7878\n",
      "Epoch 35/100\n",
      "13664/13664 [==============================] - 1s 48us/sample - loss: 0.5408 - accuracy: 0.7749 - val_loss: 0.5269 - val_accuracy: 0.7878\n",
      "Epoch 36/100\n",
      "13664/13664 [==============================] - 1s 46us/sample - loss: 0.5405 - accuracy: 0.7749 - val_loss: 0.5260 - val_accuracy: 0.7878\n",
      "Epoch 37/100\n",
      "13664/13664 [==============================] - 1s 45us/sample - loss: 0.5401 - accuracy: 0.7749 - val_loss: 0.5261 - val_accuracy: 0.7878\n",
      "Epoch 38/100\n",
      "13664/13664 [==============================] - 1s 45us/sample - loss: 0.5398 - accuracy: 0.7749 - val_loss: 0.5262 - val_accuracy: 0.7878\n",
      "Epoch 39/100\n",
      "13664/13664 [==============================] - 1s 64us/sample - loss: 0.5394 - accuracy: 0.7749 - val_loss: 0.5249 - val_accuracy: 0.7878\n",
      "Epoch 40/100\n",
      "13664/13664 [==============================] - 1s 52us/sample - loss: 0.5391 - accuracy: 0.7749 - val_loss: 0.5247 - val_accuracy: 0.7878\n",
      "Epoch 41/100\n",
      "13664/13664 [==============================] - 1s 45us/sample - loss: 0.5387 - accuracy: 0.7749 - val_loss: 0.5249 - val_accuracy: 0.7878\n",
      "Epoch 42/100\n",
      "13664/13664 [==============================] - 1s 46us/sample - loss: 0.5383 - accuracy: 0.7749 - val_loss: 0.5248 - val_accuracy: 0.7878\n",
      "Epoch 43/100\n",
      "13664/13664 [==============================] - 1s 47us/sample - loss: 0.5380 - accuracy: 0.7749 - val_loss: 0.5234 - val_accuracy: 0.7878\n",
      "Epoch 44/100\n",
      "13664/13664 [==============================] - 1s 45us/sample - loss: 0.5379 - accuracy: 0.7749 - val_loss: 0.5240 - val_accuracy: 0.7878\n",
      "Epoch 45/100\n",
      "13664/13664 [==============================] - 1s 47us/sample - loss: 0.5375 - accuracy: 0.7749 - val_loss: 0.5230 - val_accuracy: 0.7878\n",
      "Epoch 46/100\n",
      "13664/13664 [==============================] - 1s 47us/sample - loss: 0.5372 - accuracy: 0.7749 - val_loss: 0.5230 - val_accuracy: 0.7878\n",
      "Epoch 47/100\n",
      "13664/13664 [==============================] - 1s 62us/sample - loss: 0.5369 - accuracy: 0.7749 - val_loss: 0.5227 - val_accuracy: 0.7878\n",
      "Epoch 48/100\n",
      "13664/13664 [==============================] - 1s 46us/sample - loss: 0.5364 - accuracy: 0.7749 - val_loss: 0.5236 - val_accuracy: 0.7878\n",
      "Epoch 49/100\n",
      "13664/13664 [==============================] - 1s 73us/sample - loss: 0.5363 - accuracy: 0.7749 - val_loss: 0.5222 - val_accuracy: 0.7878\n",
      "Epoch 50/100\n",
      "13664/13664 [==============================] - 1s 46us/sample - loss: 0.5357 - accuracy: 0.7749 - val_loss: 0.5250 - val_accuracy: 0.7878\n",
      "Epoch 51/100\n",
      "13664/13664 [==============================] - 1s 47us/sample - loss: 0.5357 - accuracy: 0.7749 - val_loss: 0.5218 - val_accuracy: 0.7878\n",
      "Epoch 52/100\n",
      "13664/13664 [==============================] - 1s 48us/sample - loss: 0.5354 - accuracy: 0.7749 - val_loss: 0.5212 - val_accuracy: 0.7878\n",
      "Epoch 53/100\n",
      "13664/13664 [==============================] - 1s 48us/sample - loss: 0.5350 - accuracy: 0.7749 - val_loss: 0.5209 - val_accuracy: 0.7878\n",
      "Epoch 54/100\n",
      "13664/13664 [==============================] - 1s 48us/sample - loss: 0.5346 - accuracy: 0.7749 - val_loss: 0.5205 - val_accuracy: 0.7878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "13664/13664 [==============================] - 1s 49us/sample - loss: 0.5343 - accuracy: 0.7749 - val_loss: 0.5201 - val_accuracy: 0.7878\n",
      "Epoch 56/100\n",
      "13664/13664 [==============================] - 1s 46us/sample - loss: 0.5341 - accuracy: 0.7749 - val_loss: 0.5203 - val_accuracy: 0.7878\n",
      "Epoch 57/100\n",
      "13664/13664 [==============================] - 1s 47us/sample - loss: 0.5338 - accuracy: 0.7749 - val_loss: 0.5197 - val_accuracy: 0.7878\n",
      "Epoch 58/100\n",
      "13664/13664 [==============================] - 1s 47us/sample - loss: 0.5335 - accuracy: 0.7749 - val_loss: 0.5202 - val_accuracy: 0.7878\n",
      "Epoch 59/100\n",
      "13664/13664 [==============================] - 1s 48us/sample - loss: 0.5331 - accuracy: 0.7749 - val_loss: 0.5195 - val_accuracy: 0.7878\n",
      "Epoch 60/100\n",
      "13664/13664 [==============================] - 1s 48us/sample - loss: 0.5328 - accuracy: 0.7749 - val_loss: 0.5185 - val_accuracy: 0.7878\n",
      "Epoch 61/100\n",
      "13664/13664 [==============================] - 1s 45us/sample - loss: 0.5324 - accuracy: 0.7749 - val_loss: 0.5193 - val_accuracy: 0.7878\n",
      "Epoch 62/100\n",
      "13664/13664 [==============================] - 1s 45us/sample - loss: 0.5323 - accuracy: 0.7749 - val_loss: 0.5186 - val_accuracy: 0.7878\n",
      "Epoch 63/100\n",
      "13664/13664 [==============================] - 1s 46us/sample - loss: 0.5320 - accuracy: 0.7749 - val_loss: 0.5183 - val_accuracy: 0.7878\n",
      "Epoch 64/100\n",
      "13664/13664 [==============================] - 1s 45us/sample - loss: 0.5317 - accuracy: 0.7749 - val_loss: 0.5184 - val_accuracy: 0.7878\n",
      "Epoch 65/100\n",
      "13664/13664 [==============================] - 1s 45us/sample - loss: 0.5313 - accuracy: 0.7749 - val_loss: 0.5172 - val_accuracy: 0.7878\n",
      "Epoch 66/100\n",
      "13664/13664 [==============================] - 1s 44us/sample - loss: 0.5309 - accuracy: 0.7749 - val_loss: 0.5176 - val_accuracy: 0.7878\n",
      "Epoch 67/100\n",
      "13664/13664 [==============================] - 1s 47us/sample - loss: 0.5306 - accuracy: 0.7749 - val_loss: 0.5166 - val_accuracy: 0.7878\n",
      "Epoch 68/100\n",
      "13664/13664 [==============================] - 1s 48us/sample - loss: 0.5305 - accuracy: 0.7749 - val_loss: 0.5165 - val_accuracy: 0.7878\n",
      "Epoch 69/100\n",
      "13664/13664 [==============================] - 1s 45us/sample - loss: 0.5302 - accuracy: 0.7749 - val_loss: 0.5166 - val_accuracy: 0.7878\n",
      "Epoch 70/100\n",
      "13664/13664 [==============================] - 1s 46us/sample - loss: 0.5299 - accuracy: 0.7749 - val_loss: 0.5167 - val_accuracy: 0.7878\n",
      "Epoch 71/100\n",
      "13664/13664 [==============================] - 1s 48us/sample - loss: 0.5295 - accuracy: 0.7749 - val_loss: 0.5156 - val_accuracy: 0.7878\n",
      "Epoch 72/100\n",
      "13664/13664 [==============================] - 1s 47us/sample - loss: 0.5293 - accuracy: 0.7749 - val_loss: 0.5172 - val_accuracy: 0.7878\n",
      "Epoch 73/100\n",
      "13664/13664 [==============================] - 1s 49us/sample - loss: 0.5290 - accuracy: 0.7749 - val_loss: 0.5169 - val_accuracy: 0.7878\n",
      "Epoch 74/100\n",
      "13664/13664 [==============================] - 1s 60us/sample - loss: 0.5287 - accuracy: 0.7749 - val_loss: 0.5151 - val_accuracy: 0.7878\n",
      "Epoch 75/100\n",
      "13664/13664 [==============================] - 1s 46us/sample - loss: 0.5283 - accuracy: 0.7749 - val_loss: 0.5152 - val_accuracy: 0.7878\n",
      "Epoch 76/100\n",
      "13664/13664 [==============================] - 1s 49us/sample - loss: 0.5279 - accuracy: 0.7749 - val_loss: 0.5142 - val_accuracy: 0.7878\n",
      "Epoch 77/100\n",
      "13664/13664 [==============================] - 1s 47us/sample - loss: 0.5278 - accuracy: 0.7749 - val_loss: 0.5148 - val_accuracy: 0.7878\n",
      "Epoch 78/100\n",
      "13664/13664 [==============================] - 1s 48us/sample - loss: 0.5275 - accuracy: 0.7749 - val_loss: 0.5135 - val_accuracy: 0.7878\n",
      "Epoch 79/100\n",
      "13664/13664 [==============================] - 1s 48us/sample - loss: 0.5272 - accuracy: 0.7749 - val_loss: 0.5136 - val_accuracy: 0.7878\n",
      "Epoch 80/100\n",
      "13664/13664 [==============================] - 1s 47us/sample - loss: 0.5269 - accuracy: 0.7749 - val_loss: 0.5130 - val_accuracy: 0.7878\n",
      "Epoch 81/100\n",
      "13664/13664 [==============================] - 1s 49us/sample - loss: 0.5266 - accuracy: 0.7749 - val_loss: 0.5140 - val_accuracy: 0.7878\n",
      "Epoch 82/100\n",
      "13664/13664 [==============================] - 1s 48us/sample - loss: 0.5264 - accuracy: 0.7749 - val_loss: 0.5127 - val_accuracy: 0.7878\n",
      "Epoch 83/100\n",
      "13664/13664 [==============================] - 1s 47us/sample - loss: 0.5261 - accuracy: 0.7749 - val_loss: 0.5130 - val_accuracy: 0.7878\n",
      "Epoch 84/100\n",
      "13664/13664 [==============================] - 1s 47us/sample - loss: 0.5256 - accuracy: 0.7749 - val_loss: 0.5127 - val_accuracy: 0.7878\n",
      "Epoch 85/100\n",
      "13664/13664 [==============================] - 1s 47us/sample - loss: 0.5255 - accuracy: 0.7749 - val_loss: 0.5121 - val_accuracy: 0.7878\n",
      "Epoch 86/100\n",
      "13664/13664 [==============================] - 1s 46us/sample - loss: 0.5251 - accuracy: 0.7749 - val_loss: 0.5113 - val_accuracy: 0.7878\n",
      "Epoch 87/100\n",
      "13664/13664 [==============================] - 1s 47us/sample - loss: 0.5248 - accuracy: 0.7749 - val_loss: 0.5109 - val_accuracy: 0.7878\n",
      "Epoch 88/100\n",
      "13664/13664 [==============================] - 1s 45us/sample - loss: 0.5247 - accuracy: 0.7749 - val_loss: 0.5115 - val_accuracy: 0.7878\n",
      "Epoch 89/100\n",
      "13664/13664 [==============================] - 1s 45us/sample - loss: 0.5243 - accuracy: 0.7749 - val_loss: 0.5113 - val_accuracy: 0.7878\n",
      "Epoch 90/100\n",
      "13664/13664 [==============================] - 1s 45us/sample - loss: 0.5238 - accuracy: 0.7749 - val_loss: 0.5116 - val_accuracy: 0.7878\n",
      "Epoch 91/100\n",
      "13664/13664 [==============================] - 1s 47us/sample - loss: 0.5237 - accuracy: 0.7749 - val_loss: 0.5106 - val_accuracy: 0.7878\n",
      "Epoch 92/100\n",
      "13664/13664 [==============================] - 1s 46us/sample - loss: 0.5234 - accuracy: 0.7749 - val_loss: 0.5108 - val_accuracy: 0.7878\n",
      "Epoch 93/100\n",
      "13664/13664 [==============================] - 1s 47us/sample - loss: 0.5230 - accuracy: 0.7749 - val_loss: 0.5092 - val_accuracy: 0.7878\n",
      "Epoch 94/100\n",
      "13664/13664 [==============================] - 1s 45us/sample - loss: 0.5228 - accuracy: 0.7749 - val_loss: 0.5098 - val_accuracy: 0.7878\n",
      "Epoch 95/100\n",
      "13664/13664 [==============================] - 1s 45us/sample - loss: 0.5223 - accuracy: 0.7749 - val_loss: 0.5103 - val_accuracy: 0.7878\n",
      "Epoch 96/100\n",
      "13664/13664 [==============================] - 1s 47us/sample - loss: 0.5222 - accuracy: 0.7749 - val_loss: 0.5083 - val_accuracy: 0.7878\n",
      "Epoch 97/100\n",
      "13664/13664 [==============================] - 1s 45us/sample - loss: 0.5218 - accuracy: 0.7749 - val_loss: 0.5085 - val_accuracy: 0.7878\n",
      "Epoch 98/100\n",
      "13664/13664 [==============================] - 1s 45us/sample - loss: 0.5216 - accuracy: 0.7749 - val_loss: 0.5084 - val_accuracy: 0.7878\n",
      "Epoch 99/100\n",
      "13664/13664 [==============================] - 1s 46us/sample - loss: 0.5210 - accuracy: 0.7749 - val_loss: 0.5076 - val_accuracy: 0.7878\n",
      "Epoch 100/100\n",
      "13664/13664 [==============================] - 1s 47us/sample - loss: 0.5209 - accuracy: 0.7749 - val_loss: 0.5071 - val_accuracy: 0.7878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24b760de048>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_nn.fit(X_train_part, y_train_part, epochs = 100, validation_data = (X_valid, y_valid), callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All 3 of the extra models that we've tried yielded very similar results as our logistic regression model, an accuracy of about 77%. It seems that in this case, using more advanced models did not give us better results. I suspect that this is due to the limits of our training data, afterall we are technically only using 3 predictor variables. If we wanted to get a higher accuracy, I would suggest going back to look at things such as the distribution of the Race variable, adding in addition variables, or perhaps using Grades instead of Age as a predictor variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
